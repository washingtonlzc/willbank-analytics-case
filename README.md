# Will Bank ‚Äì Case T√©cnico: Senior Analytics Engineer

**Autor:** Washington (Kim)

## Sum√°rio

- [Objetivo do Case](#objetivo-do-case)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Arquitetura do Pipeline](#arquitetura-da-pipeline)
- [Como Executar o Projeto](#como-executar-o-projeto)
- [Principais M√©tricas e KPIs](#principais-m√©tricas-kpis)
- [Exemplo de An√°lise Explorat√≥ria (EDA)](#exemplo-de-an√°lise-explorat√≥ria-eda)
- [Plano de Integra√ß√£o de Dados Externos (NPS)](#plano-de-integracao-de-dados-externos-nps)
- [Sugest√µes de Governan√ßa e Melhoria](#sugestoes-tecnicas-e-de-governanca)
- [Status do Projeto](#status-do-projeto)

---

## Objetivo do Case

Este projeto apresenta a solu√ß√£o para o case t√©cnico da vaga de **Senior Analytics Engineer** no Will Bank. O objetivo principal foi desenvolver um **pipeline de dados robusto e escal√°vel em m√∫ltiplas camadas** (Raw ‚Üí Bronze ‚Üí Silver ‚Üí Gold), com foco em:

* **Detec√ß√£o de Inconsist√™ncias**: Identificar falhas e inconsist√™ncias em transa√ß√µes PIX.
* **Enriquecimento de Dados**: Agregar valor aos dados transacionais com informa√ß√µes demogr√°ficas dos clientes.
* **Proposta de Evolu√ß√£o**: Sugerir a ingest√£o de dados via API externa para enriquecimento cont√≠nuo.
* **Vis√£o Estrat√©gica**: Apresentar sugest√µes t√©cnicas e de neg√≥cio que v√£o al√©m do escopo solicitado, visando a melhoria cont√≠nua dos processos de dados.

---

## Estrutura do Projeto

O reposit√≥rio est√° organizado de forma a garantir a rastreabilidade, manutenibilidade e clareza do fluxo de dados, desde a origem at√© a camada de consumo.

```bash
willbank-analytics-case/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                          # Dados originais fornecidos (core_account, core_pix, customer)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core_account.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core_pix.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ customer.csv
‚îÇ   ‚îú‚îÄ‚îÄ bronze/                       # Dados tratados e padronizados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bronze_core_account.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bronze_core_pix.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ bronze_customer.csv
‚îÇ   ‚îú‚îÄ‚îÄ silver/                       # Dados enriquecidos, cruzamentos e an√°lises intermedi√°rias
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ silver_inconsistencias.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ silver_pix_falhou_registro.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ silver_pix_falhou_registro_com_uf.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ silver_pix_transacoes.csv 
‚îÇ   ‚îî‚îÄ‚îÄ gold/                         # Dados agregados e KPIs finais
‚îÇ       ‚îú‚îÄ‚îÄ gold_clientes_por_uf.csv
‚îÇ       ‚îú‚îÄ‚îÄ gold_estatisticas_idade.csv
‚îÇ       ‚îú‚îÄ‚îÄ gold_falhas_por_dia.csv
‚îÇ       ‚îú‚îÄ‚îÄ gold_falhas_por_hora.csv
‚îÇ       ‚îú‚îÄ‚îÄ gold_falhas_por_uf.csv
‚îÇ       ‚îú‚îÄ‚îÄ gold_ranking_falhas_por_uf.csv
‚îÇ       ‚îú‚îÄ‚îÄ gold_taxa_sucesso_pix_percentual.csv
‚îÇ       ‚îú‚îÄ‚îÄ gold_taxa_sucesso_pix_quantidade.csv
‚îÇ       ‚îú‚îÄ‚îÄ gold_total_pix_por_tipo.csv
‚îÇ       ‚îú‚îÄ‚îÄ gold_total_pix_por_uf.csv
‚îÇ       ‚îú‚îÄ‚îÄ gold_transacoes_suspeitas.csv
‚îÇ       ‚îú‚îÄ‚îÄ gold_transacoes_suspeitas_resumo.txt
‚îÇ       ‚îî‚îÄ‚îÄ gold_valor_medio_pix_mensal.csv
‚îÇ
‚îú‚îÄ‚îÄ deliverables/                    # Resultados finais e artefatos para apresenta√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ dashboard/                   # Imagens e links de dashboards (ex: Looker)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ link_para_o_dashboard_online.md
‚îÇ   ‚îú‚îÄ‚îÄ docs/                       # Documentos auxiliares e suporte
‚îÇ   ‚îî‚îÄ‚îÄ output/                     # Gr√°ficos, relat√≥rios e imagens exportadas
‚îÇ       ‚îú‚îÄ‚îÄ falhas_por_dia.png
‚îÇ       ‚îî‚îÄ‚îÄ ranking_falhas_por_uf.png
‚îÇ
‚îú‚îÄ‚îÄ scripts/                        # Scripts organizados por camada do pipeline
‚îÇ   ‚îú‚îÄ‚îÄ validation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ testa_falhas_por_uf.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ verifica_e_roda_pipeline.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ verifica_surrogate_key_cliente.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ verifica_surrogate_key_falhas.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ verifica_uf_falhas.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ verifica_uf_nos_bronze.py
‚îÇ   ‚îú‚îÄ‚îÄ bronze_transform.py         # Tratamento inicial e padroniza√ß√£o (Bronze)
‚îÇ   ‚îú‚îÄ‚îÄ silver_transform.py         # Enriquecimento e uni√£o de dados (Silver)
‚îÇ   ‚îú‚îÄ‚îÄ silver_inconsistencias.py  # Detec√ß√£o de inconsist√™ncias na camada Silver
‚îÇ   ‚îú‚îÄ‚îÄ silver_pix_falhou_registro.py # Identifica√ß√£o de falhas em registros PIX (Silver)
‚îÇ   ‚îú‚îÄ‚îÄ gold_kpis.py                # Gera√ß√£o dos principais KPIs (Gold)
‚îÇ   ‚îú‚îÄ‚îÄ gold_kpis_demografia.py    # KPIs demogr√°ficos (idade, UF) (Gold)
‚îÇ   ‚îú‚îÄ‚îÄ gold_kpis_estrategicos.py  # KPIs estrat√©gicos (falhas, suspeitas) (Gold)
‚îÇ   ‚îú‚îÄ‚îÄ gold_falhas_temporais.py   # An√°lise temporal de falhas (Gold)
‚îÇ   ‚îú‚îÄ‚îÄ gold_ranking_falhas_por_uf.py # Ranking de falhas por UF (Gold)
‚îÇ   ‚îî‚îÄ‚îÄ teste.ipynb                 # Scripts auxiliares para testes
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt               # Depend√™ncias Python do projeto
‚îú‚îÄ‚îÄ README.md                     # Documenta√ß√£o principal do projeto
‚îî‚îÄ‚îÄ .gitignore                    # Configura√ß√µes para Git

````

-----

## Arquitetura do Pipeline

O pipeline foi constru√≠do seguindo a metodologia **Medallion Architecture** para garantir qualidade e governan√ßa.

### Notas sobre a Implementa√ß√£o e SQL

Como os dados disponibilizados para o case est√£o em formato CSV e n√£o em um banco de dados real, optei por utilizar o Pandas para realizar as transforma√ß√µes e an√°lises localmente. O Pandas permite simular praticamente todos os comandos SQL cl√°ssicos, como SELECT, JOIN e GROUP BY, ent√£o consigo aplicar as regras do pipeline sem perder nenhuma funcionalidade.

Para garantir o que foi solicitado, inclu√≠ exemplos de como cada etapa poderia ser feita em SQL, seja nos coment√°rios dos scripts ou no README do projeto, deixando claro que todo o processo pode ser facilmente adaptado para qualquer engine SQL em um ambiente de Data Lake real.

## Exemplo de Transforma√ß√£o Silver

```sql
-- Exemplo conceitual da transforma√ß√£o Silver: Unificando PIX, Account e Customer
-- Equivalente √† l√≥gica do silver_transform.py

SELECT
    p.id_end_to_end,
    p.dt_transaction,
    p.vl_transaction,
    p.ds_transaction_type AS pix_transaction_type,
    ca.cd_account_customer,
    c.full_name,
    c.birth_date,
    c.uf,
    CASE
        WHEN c.surrogate_key IS NOT NULL THEN 'Sucesso'
        ELSE 'Falha'
    END AS status_transacao,
    -- Outras colunas e c√°lculos, como idade e transacao_suspeita,
    -- seriam adicionados aqui ou em etapas posteriores.
    CURRENT_DATE AS dt_ingestion -- Data de ingest√£o para rastreabilidade
FROM
    bronze_core_pix p
LEFT JOIN
    bronze_core_account ca ON p.cd_seqlan = ca.cd_seqlan
LEFT JOIN
    bronze_customer c ON ca.surrogate_key = c.surrogate_key;
```

### Detec√ß√£o de Inconsist√™ncia

* **Contexto:** PIX em Account que falhou no Core PIX
* **Equivalente √† l√≥gica do:** `silver_pix_falhou_registro.py`

```sql
-- Exemplo conceitual da detec√ß√£o de inconsist√™ncia: PIX em Account que falhou no Core PIX
-- Equivalente √† l√≥gica do silver_pix_falhou_registro.py

SELECT
    a.id_transaction,
    a.dt_transaction,
    a.cd_account_customer,
    a.vl_transaction
FROM
    bronze_core_account a
WHERE
    a.ds_transaction_type = 'PIX'
    AND NOT EXISTS (
        SELECT 1
        FROM bronze_core_pix p
        WHERE p.cd_seqlan = a.cd_seqlan
    );
```

### 1\. Camada Raw

* **Origem:** `data/raw/`
  * **Descri√ß√£o:** Cont√©m os dados brutos fornecidos no formato CSV, sem nenhuma modifica√ß√£o.
      * `core_account.csv`
      * `core_pix.csv`
      * `customer.csv`

### 2\. Camada Bronze

  * **Origem:** `data/bronze/`
  * **Script:** `scripts/bronze_transform.py`
  * **Descri√ß√£o:** Primeira etapa de tratamento e padroniza√ß√£o. As principais transforma√ß√µes incluem:
      * Ajuste e convers√£o de tipos de dados (`datetime`, `float`, `int`).
      * Padroniza√ß√£o de nomes de colunas.
      * Cria√ß√£o da coluna `dt_ingestion` para rastreabilidade.
  * **Sa√≠das:**
      * `bronze_core_account.csv`
      * `bronze_core_pix.csv`
      * `bronze_customer.csv`

### 3\. Camada Silver

  * **Origem:** `data/silver/`
  * **Scripts:** `scripts/silver_transform.py`, `scripts/silver_inconsistencias.py`, etc.
  * **Descri√ß√£o:** Camada de enriquecimento e consolida√ß√£o, onde os dados s√£o cruzados para gerar insights.
      * **Join Estrat√©gico:** As bases s√£o unificadas na vis√£o PIX ‚Üí Account ‚Üí Customer para criar uma tabela anal√≠tica central.
      * **An√°lises de Inconsist√™ncia:** Scripts dedicados identificam e isolam anomalias nos dados.
  * **Sa√≠das Principais:**
      * `silver_pix_transacoes.csv`: Tabela consolidada com todas as transa√ß√µes PIX, informa√ß√µes da conta e dados demogr√°ficos do cliente.
      * `silver_pix_falhou_registro.csv`: Transa√ß√µes PIX identificadas no `core_account` que n√£o possuem registro correspondente no `core_pix`.
      * `silver_inconsistencias.csv`: Entradas no `core_pix` que n√£o possuem uma conta correspondente em `core_account`, apontando para poss√≠veis problemas de integridade referencial.

### 4\. Camada Gold

  * **Origem:** `data/gold/`
  * **Descri√ß√£o:** Camada final, projetada para consumo por stakeholders e ferramentas de BI. Cont√©m dados agregados, KPIs e m√©tricas de neg√≥cio prontas para an√°lise.
  * **Exemplos de Sa√≠das:**
      * `gold_taxa_sucesso_pix.csv`
      * `gold_falhas_por_uf.csv`
      * `gold_valor_medio_pix_mensal.csv`
      * `gold_transacoes_suspeitas.csv`
      * `gold_estatisticas_idade.csv`
      * `gold_clientes_por_uf.csv`
      * `gold_total_pix_por_tipo.csv`
      * `gold_total_pix_por_uf.csv`
-----

## üìä Dashboard Gerencial (Streamlit)

O projeto conta com um **dashboard interativo desenvolvido em Streamlit**, que consolida os principais KPIs e insights extra√≠dos do pipeline, facilitando a an√°lise executiva e a apresenta√ß√£o para o time de neg√≥cios.

**Principais caracter√≠sticas:**
- Visualiza√ß√£o din√¢mica dos KPIs PIX (taxa de sucesso/falha, volume por status)
- An√°lise temporal de falhas (por dia da semana e ranking de UFs)
- Distribui√ß√£o demogr√°fica dos clientes (UF e idade)
- Detec√ß√£o de outliers (transa√ß√µes suspeitas)
- Propostas de evolu√ß√£o e governan√ßa, integradas √† vis√£o estrat√©gica do case
- **Cores e layout seguem a identidade visual do Will Bank (roxo, amarelo, azul claro)**

**Como executar:**

```bash
pip install streamlit plotly pandas
streamlit run scripts/dashboard.py
```
-----


### Principais M√©tricas e KPIs

A partir do pipeline estruturado at√© a camada Gold, foram extra√≠das as seguintes m√©tricas e an√°lises, proporcionando uma vis√£o abrangente do neg√≥cio e subsidiando a tomada de decis√£o:

* üìà **Taxa de Sucesso das Transa√ß√µes PIX**
* ‚ùå **Taxa de Falha/Inconsist√™ncia PIX**
* üåé **Distribui√ß√£o de Clientes por UF**
* üëµ **Distribui√ß√£o Et√°ria dos Clientes**
* üèÜ **Ranking de UFs com Mais Erros**
* ‚è∞ **Falhas por Dia**
* üö® **Proposta de Alerta Autom√°tico** (quando taxa de sucesso cair abaixo de um limiar cr√≠tico)
* üí∞ **Valor M√©dio Mensal das Transa√ß√µes**
* üïµÔ∏è **Transa√ß√µes Suspeitas** (Outliers)


### Distribui√ß√£o Et√°ria dos Clientes
...
(descri√ß√£o dessa an√°lise)

## Longevidade at√© o Primeiro PIX

Foi calculado o tempo (em dias) entre a data de abertura da conta e a data da primeira transa√ß√£o PIX de cada cliente.  
Esse indicador mede o engajamento inicial do cliente com o PIX e pode indicar oportunidades para campanhas de ativa√ß√£o, educa√ß√£o ou melhorias no onboarding.

- **M√©dia de dias at√© o 1¬∫ PIX:** 27 dias  
- **Mediana:** 36 dias  
- **Quartis:** 25% (-21), 75% (86)  
- **M√≠nimo:** -207 dias (poss√≠vel erro de cadastro ou retroalimenta√ß√£o do sistema)  
- **M√°ximo:** 177 dias

> Valores negativos sugerem inconsist√™ncias cadastrais ou processos retroativos de registro, recomendando revis√£o nos sistemas de origem.

*Detalhes completos dispon√≠veis em:*  
`data/gold/gold_longevidade_primeiro_pix.csv`  
`data/gold/gold_longevidade_primeiro_pix_resumo.txt`

### KPIs e Propostas Estrat√©gicas
...


## Taxa de Sucesso nas Transa√ß√µes PIX

Para melhor compreens√£o e an√°lise do desempenho das transa√ß√µes PIX, foram gerados dois arquivos distintos contendo informa√ß√µes complementares sobre o status das transa√ß√µes:

- **`gold_taxa_sucesso_pix_percentual.csv`**  
  Cont√©m a distribui√ß√£o percentual das transa√ß√µes categorizadas por status (por exemplo, "Sucesso" e "Falha").  
  Este arquivo ajuda a entender a propor√ß√£o relativa de transa√ß√µes bem-sucedidas versus as que apresentaram falhas, facilitando a an√°lise do desempenho global do sistema.

- **`gold_taxa_sucesso_pix_quantidade.csv`**  
  Apresenta o n√∫mero absoluto de transa√ß√µes para cada categoria de status.  
  Esta informa√ß√£o √© crucial para contextualizar o percentual, pois revela o volume real de transa√ß√µes em cada categoria, permitindo avaliar a signific√¢ncia estat√≠stica das m√©tricas apresentadas.

### Exemplo de Uso

Ao analisar o percentual de sucesso de 98%, √© importante tamb√©m considerar que esse percentual representa, por exemplo, 1.000.000 de transa√ß√µes bem-sucedidas e 20.000 falhas. Dessa forma, ambos os arquivos devem ser utilizados em conjunto para garantir uma vis√£o completa da qualidade do servi√ßo.

### Exemplos de An√°lises e Insights

Ap√≥s a detec√ß√£o de inconsist√™ncias entre as camadas Core Account e Core PIX, foram realizadas an√°lises temporais para identificar padr√µes de falhas:

**Falhas por Dia da Semana:**
> A an√°lise revelou que a maior parte das falhas de PIX ocorreu nas segundas e quartas-feiras, totalizando mais de 320 ocorr√™ncias em cada um desses dias, enquanto a sexta-feira apresentou um volume significativamente menor. Este padr√£o pode indicar gargalos operacionais ou picos de uso nessas datas, sugerindo a necessidade de investiga√ß√£o direcionada e poss√≠vel refor√ßo de monitoramento ou recursos nesses per√≠odos.

**Falhas por Hora do Dia:**
> (Insira aqui o insight do gr√°fico por hora, se gerou.)

**Gr√°ficos:**
- ![Falhas por dia da semana](deliverables/output/falhas_por_dia.png)

Esses insights permitem √† equipe t√©cnica priorizar esfor√ßos e prever janelas de maior risco, refor√ßando a robustez do pipeline implementado.

## Exemplo de An√°lise Explorat√≥ria (EDA)

Antes do desenvolvimento completo do pipeline, foi realizada uma an√°lise explorat√≥ria dos dados (EDA) para identificar padr√µes, avaliar a qualidade e levantar poss√≠veis inconsist√™ncias.  
O notebook completo da EDA, com gr√°ficos e insights, pode ser consultado em [`scripts/eda_willbank.ipynb`](scripts/eda_willbank.ipynb).

### Exemplo de insight visual:
![Exemplo de gr√°fico temporal de transa√ß√µes](deliverables/output/falhas_por_dia.png)

> *Exemplo:* O gr√°fico acima mostra que as falhas de PIX se concentram principalmente em determinados dias da semana, o que pode indicar gargalos operacionais e orientar o refor√ßo de monitoramento em datas cr√≠ticas.

Outros exemplos de insights extra√≠dos:
- Evolu√ß√£o di√°ria do volume de transa√ß√µes PIX
- Distribui√ß√£o de valores de transa√ß√£o (identifica√ß√£o de outliers)
- Perfil geogr√°fico e et√°rio dos clientes

*Para detalhes completos da an√°lise explorat√≥ria, consulte o notebook na pasta `/scripts/`.*


## KPIs e Propostas Estrat√©gicas

Al√©m da constru√ß√£o do pipeline, foram geradas m√©tricas e propostas de valor para o neg√≥cio.

### M√©tricas Implementadas

  * **Volume de Transa√ß√µes com Falha:** Quantifica√ß√£o das transa√ß√µes que falharam no registro.
  * **Identifica√ß√£o de Transa√ß√µes Suspeitas:** An√°lise de outliers com base em valores monet√°rios (ex: transa√ß√µes com valor muito acima da mediana do cliente ou do sistema).
  * **Enriquecimento Demogr√°fico:** Cruzamento de dados transacionais com idade e estado (UF) do cliente para an√°lises comportamentais.

### Propostas de Melhoria e An√°lise

1.  **Taxa de Falha por Tipo de Transa√ß√£o:** Calcular a propor√ß√£o de falhas para cada tipo de chave PIX (CPF, e-mail, celular, aleat√≥ria).
2.  **An√°lise Geogr√°fica e Demogr√°fica:**
      * Distribui√ß√£o de clientes por estado (UF).
      * Distribui√ß√£o et√°ria dos clientes (idade m√©dia, quartis, histograma).
      * Ranking de UFs com maior taxa de erro em transa√ß√µes PIX.
3.  **An√°lise Temporal:** Estudo do padr√£o de falhas ao longo do tempo (por dia da semana) para identificar poss√≠veis gargalos em momentos de pico.
4.  **Monitoramento e Alertas:** Proposta de implementa√ß√£o de um alerta autom√°tico (via Slack ou e-mail) caso a taxa de sucesso das transa√ß√µes PIX caia abaixo de um limiar cr√≠tico (ex: 98%).
5.  **Visualiza√ß√£o de Dados:** Simula√ß√£o de um dashboard em Power BI ou Metabase para acompanhamento cont√≠nuo dos KPIs pela √°rea de neg√≥cio (dispon√≠vel em `deliverables/dashboard/`).

-----

## Sugest√µes de Governan√ßa e Melhoria

Para garantir a evolu√ß√£o e a sustentabilidade da solu√ß√£o, as seguintes melhorias s√£o propostas:

### 1. Plano de Integra√ß√£o de Dados Externos (NPS)

Para integrar os dados da pesquisa de satisfa√ß√£o do cliente (NPS) fornecidos via API externa, conforme solicitado, prop√µe-se o seguinte plano de a√ß√£o detalhado em t√≥picos, alinhado √† arquitetura Medallion:

* **1.1. Origem e Frequ√™ncia:**
    * **Origem:** Dados de NPS disponibilizados mensalmente por um fornecedor externo via API.
    * **Frequ√™ncia:** Ingest√£o agendada para ocorrer uma vez ao m√™s, ap√≥s a disponibiliza√ß√£o dos dados pela API.

* **1.2. Camada Bronze (Ingest√£o e Armazenamento Bruto):**
    * **Mecanismo de Ingest√£o:** Desenvolvimento de um script Python dedicado (e.g., `scripts/nps_ingest.py`) que se conectaria √† API externa. Este script seria respons√°vel por:
        * Gerenciar a autentica√ß√£o e autoriza√ß√£o junto √† API (ex: uso de chaves API ou tokens).
        * Realizar requisi√ß√µes HTTP para coletar os dados da pesquisa.
        * Implementar mecanismos de re-tentativa e tratamento de erros de conex√£o/resposta da API.
    * **Formato de Armazenamento:** Os dados brutos da API (provavelmente em JSON) seriam salvos "as-is" (como recebidos) em formato Parquet ou CSV na pasta `data/bronze/nps/`.
    * **Metadados e Rastreabilidade:** Adicionar colunas de metadados como `dt_ingestion` (data da coleta), `api_version` (se aplic√°vel), e `process_id` para garantir a auditabilidade e reprocessamento, se necess√°rio.

* **1.3. Camada Silver (Tratamento e Enriquecimento):**
    * **Mecanismo de Transforma√ß√£o:** Um script Python (e.g., `scripts/silver_nps_transform.py`) seria desenvolvido para:
        * **Normaliza√ß√£o:** Padronizar nomes de colunas, ajustar tipos de dados (e.g., datas, scores num√©ricos) e garantir a consist√™ncia dos valores.
        * **Tratamento de Qualidade:** Lidar com valores nulos ou inconsistentes (ex: preenchimento, remo√ß√£o ou sinaliza√ß√£o).
        * **Deduplica√ß√£o:** Garantir a unicidade dos registros de NPS para evitar contagens duplas em an√°lises.
        * **Enriquecimento:** Realizar um `JOIN` com os dados de `customer` (da `bronze_customer.csv` ou `silver_customer.csv` se j√° existisse uma espec√≠fica) utilizando o `surrogate_key` do cliente. Isso agregaria informa√ß√µes demogr√°ficas (idade, UF, etc.) √†s respostas de NPS, permitindo an√°lises contextuais.
    * **Sa√≠da:** A tabela `silver_nps_data.csv` (ou Parquet) seria salva na pasta `data/silver/nps/`, contendo os dados de NPS limpos e enriquecidos.

* **1.4. Camada Gold (Consumo e KPIs):**
    * **Mecanismo de Agrega√ß√£o:** Scripts Python (e.g., `scripts/gold_nps_kpis.py`) seriam criados para gerar m√©tricas e cubos de neg√≥cio a partir da `silver_nps_data.csv`.
    * **Exemplos de KPIs e An√°lises:**
        * NPS m√©dio por m√™s, por regi√£o (UF) e por faixa et√°ria.
        * Correla√ß√£o entre o NPS e a taxa de sucesso de transa√ß√µes PIX (cruzando com `gold_taxa_sucesso_pix.csv`).
        * Identifica√ß√£o de segmentos de clientes com baixo NPS para a√ß√µes de melhoria.
        * Visualiza√ß√£o das tend√™ncias de NPS ao longo do tempo.
    * **Sa√≠da:** Arquivos sumarizados (e.g., `gold_nps_mensal.csv`, `gold_nps_por_uf.csv`) seriam salvos na pasta `data/gold/`.

* **1.5. Considera√ß√µes Adicionais para Robustez:**
    * **Idempot√™ncia:** Projetar o processo para que m√∫ltiplas execu√ß√µes do script de ingest√£o (dentro de um mesmo per√≠odo mensal) n√£o resultem em duplica√ß√£o de dados, seja por verifica√ß√£o de chaves ou estrat√©gia de "upsert".
    * **Observabilidade:** Implementar logging detalhado para monitorar a execu√ß√£o, erros da API e volumes de dados.
    * **Alertas:** Configurar alertas (e.g., via e-mail ou Slack) para falhas na ingest√£o ou anomalias nos dados de NPS (ex: queda abrupta do score).
    * **Versionamento:** Garantir que o c√≥digo da ingest√£o e as defini√ß√µes das tabelas sejam versionados no Git, e considerar o uso de ferramentas como DVC para versionar os pr√≥prios datasets de NPS.



1.  **Ingest√£o de Dados Externos (NPS):** Planejamento para ingest√£o de dados de satisfa√ß√£o do cliente (NPS) via API. Isso permitiria correlacionar a experi√™ncia do cliente com a performance de produtos como o PIX.
2.  **Governan√ßa de Dados:**
      * **Versionamento de Dados:** Implementar o versionamento dos datasets (ex: com DVC) para garantir reprodutibilidade.
      * **Testes de Integridade:** Criar um framework de testes automatizados (ex: Great Expectations) para validar a qualidade dos dados a cada execu√ß√£o do pipeline.
      * **Score de Confiabilidade:** Desenvolver um health score dos dados, que me√ßa a qualidade, atualidade e completude das tabelas cr√≠ticas.
3.  **An√°lise de Impacto Financeiro:** Estimar o impacto financeiro das falhas PIX, considerando custos operacionais de suporte e o potencial churn de clientes insatisfeitos.



---

## Status do Projeto

‚úÖ **Pipeline Implementado:** As camadas Raw ‚Üí Bronze ‚Üí Silver ‚Üí Gold est√£o completas.
‚úÖ **An√°lises Estrat√©gicas:** KPIs e an√°lises de neg√≥cio foram desenvolvidos.
‚úÖ **Pronto para Expans√£o:** Projeto estruturado para futuras integra√ß√µes via API e visualiza√ß√£o em ferramentas de BI.

---

## Como Executar o Projeto

Para replicar o ambiente e executar o pipeline, siga os passos abaixo:

1.  **Pr√©-requisitos:** Certifique-se de ter o Python (vers√£o 3.x) e o `pip` instalados em sua m√°quina.

2.  **Instalar Depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Executar o Pipeline:**
    Siga a ordem de execu√ß√£o das camadas para processar os dados:

    * **Camada Bronze:**
        ```bash
        python scripts/bronze_transform.py
        ```
    * **Camada Silver:**
        ```bash
        python scripts/silver_transform.py
        python scripts/silver_inconsistencias.py
        python scripts/silver_pix_falhou_registro.py
        ```
    * **Camada Gold:**
        ```bash
        python scripts/gold_kpis.py
        python scripts/gold_kpis_demografia.py
        python scripts/gold_kpis_estrategicos.py
        python scripts/gold_falhas_temporais.py
        python scripts/gold_ranking_falhas_por_uf.py
        ```

    Ap√≥s a execu√ß√£o, os resultados e as sa√≠das processadas estar√£o dispon√≠veis nas respectivas pastas (`data/bronze`, `data/silver`, `data/gold`, e `deliverables/output`).
---
## Observa√ß√µes Finais
* O projeto busca refletir pr√°ticas reais de engenharia de dados em larga escala.
* Foi constru√≠do para ser simples de testar, manter e escalar.
* Todos os scripts est√£o separados por camada e responsabilidade.
* Aberto a sugest√µes e discuss√µes para evoluir a solu√ß√£o e contribuir com o time Will Bank!
